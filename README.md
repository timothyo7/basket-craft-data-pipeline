This project repository implements an end-to-end data pipeline for Basket Craft's e-commerce analytics. The pipeline extracts data from a MySQL source database (products, orders, and website sessions), loads it into a PostgreSQL raw schema, and transforms it through a modular dbt workflow with staging and warehouse layers. The architecture follows modern ELT principles, enabling separate storage and compute while maintaining data lineage. Using Python and SQLAlchemy for extraction, dbt for transformation, and GitHub Actions for automation, the pipeline runs every 15 minutes to ensure fresh data availability. The warehouse layer produces fact tables including website session metrics by UTM source, enabling stakeholders to analyze traffic patterns, repeat visit rates, and marketing channel effectiveness through interactive Looker Studio dashboards with cross-filtering capabilities.